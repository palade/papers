{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset128 HiraKakuProN-W3;\f2\froman\fcharset0 Times-Roman;
\f3\fnil\fcharset134 STHeitiSC-Light;\f4\froman\fcharset0 TimesNewRomanPSMT;\f5\fswiss\fcharset0 ArialMT;
\f6\fnil\fcharset0 Verdana;}
{\colortbl;\red255\green255\blue255;\red154\green154\blue154;\red179\green179\blue179;\red128\green128\blue128;
\red164\green8\blue0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh7720\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf0 Self-managed and fine grained SLA guarantee in the cloud\
adaptive fine grandee SLA  pareto optimisation and economic equilibrium enforcement\
\
Problems list:\
1) no consider relationship/interference amongst different attributes, and services\
no relationship consideration of attributes and service cause possible reactive to enforce SLA needs to be predefined. what parameter needs to consider can be defined e.g. bandwidth, CPU but what action needs to perform should be avoid.\
\
2) no consider business reason towards such attributes\
\
3) no consideration of consistency\
\
4) no prediction, thus how much resource we need to increase? Notice when add/remove resource we still consider the granularity of per application since it is really difficult to ensure such resource are used by certain services\
\
\
5) only focus driven on single/limited attribute, such as resource and performance\
\
6) not many to define on fine grained service, but rather see an application has a constant SLA
\f1 \'81\'43
\f0  thus not fine grained.\
\
7) most approach suffer look backward issue - based on past environmental condition to cnofig new interval, expecting the same violation does not occur. May consequently result in too many re-condifg over time. \
\
8) solutions for MOO may lack of consideration of distributed architecture while other solution suffer issue 7).\
\
9
\f1 \'81\'6a
\f0 market price fluctuations such as spot instance can result int SLA violation as they can not determine the demand. Consumers need to manually estimate their need, which is unrealistic, currently only based on bid price, which could not fully represent demand.\
\
10) in on-demand manner, the iaas SLA may not be need as no need to specify how much resource needed but how much willing to pay for. (exception would be reserve resource)\
\
11) no consideration of interference (such as static modeling of SLA), not intend to handle such interference but try to avoid it when modelling (such as those dynamic modelling papers)\
\
12) for resource allocation paper, usually do not consider user friendly SLA terms.\
\
ANN may be better for regression for long time prediction, however, regression is more efficient and accurate enough on short time period.\
\
Our approach consider both consumer (pareto optimal and minimum cost via change control value) and provider (maximum profit via change price)\
\
Helpful techniques from literature:\
use of  Exponentially Weighted Moving Average (EWMA)  therefore to avoid occasionally peak in a very short period of time.\
\
0596173, ccgrid, ec2price and CIT2009 could be helpful for question 4)\
\
AutonomicSLA-Cloud could be helpful to determine monitor interval\
\
HPCS - IWCMC Vincent, Compsac 2010 I. Brandic and Emeakaroha_CloudComp2010 could be useful for overall architecture of self managing SLA\
\
HPCS - IWCMC Vincent can also benefits to transfer SLA parameter to monetary cost\
\
ccgrid could be useful to adapt a coefficient strategy for load balancing. This may be useful when considering which node to perform resizing\
\
Cloud11_Autoscaling provide good prediction model autoregressive moving average method (ARMA) can be used for predict workload. 6119065 also use queue theory to predict latency.\
\
iwcs, 6119065 can be used for multi-objective optimisation problem.\
\
service demand law may be helpful for determine resource used per service, this is mentioned in ICPE11_MAQPRO which also can be useful for MVA\
\
various papers in dynamic modelling can be used for create dynamic model of relations. such as q-cloud.\
\
GECON10, TR10 can be useful to unifying resource such as cpu\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs30 \cf0 Potential theory involved (each subject to minor modifications):\
\
relations of attribute: (for fitness function)
\fs24 \
 Mean Value Analysis, queue theory,  \uc0\u8234 Birth\'96death process\uc0\u8236 , Erlang
\fs38 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f1\fs24 \cf0 \

\f0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs30 \cf0 Finding optimal config of services and attributes:
\fs24 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs26 \cf0 Multi-objective optimization (popular)
\f1 \'81\'43
\f0  genetic algorithm
\fs24 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs30 \cf0 resource efficiency:
\fs24 \
supply demand theory, partial equilibrium \
\

\fs30 Adaptive systems:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs24 \cf0 adaptive MAPE loop, MPC, CBR, prediction theory,\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs30 \cf0 Managing SLA in cloud:
\fs24 \
Heuristics-base:\
Market based theory, CBR, queue theory\
\
Control-theoretic:\
control theory\
\
\
\
\
\
\
(fine grande service could be helpful to determine what is the consumer really demand)\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\fs28 \cf0 Current though:
\fs24 \
\
predict or not or hybrid? estimate != predict\
\
0. SLA model could be expose model that handles \{SLA-infrastrcutre, SLA-platform\} - (model) - SLA-software (to end user). It can be extended to form end to end SLA as well, but each type of user group (i.e. gold, silver) need to use different instance of service (2 different instance of service A)\
\
Pareto optimal fined grained SLA means for each service, it contains conflict objective such as least adj to achieve highest mon, most strict consistency to best performance etc.\
\
1. (application of queuing theory to model consistency queue) can used a list of global workload time interval e.g. a day or a year for each region queue.  also record occurrence of whole region and percentage of occurrence of each related services. When adaption get the expected number of request to that region (using non-homogeneous poisson process) then make trade-off to make the SLA >= response time of mixture of consistency level of related service with number of expected - 1 (assume the request to A occur at last, worst case)\
\
1.1 if not predict, observe  queue size for each region and calculate the timeliness of observe last request for each services, if violate trigger GA  , still can apply Litter's law to adjust monitoring interval. Or a monitoring would be trigger by each request\
\
(or using simp weight average for global workload time interval for each service)\
\
\
2. trigger can be based on violation found or global monitoring time interval reach, on a predictable-manner even when the SLA parameters are actively changed.\
\
3. We define component level region (for cpu memory) and service level region (CR and SCR for consistency), which are hierarchical. Each region may have different type such as CR, SCR. We specify what service should be consistent and translate to CDS in SSOR. of course it would have many CDS for a service in SCR. Each service region may have different components. We do not considering consistency between components, as it can not ensure what sequence a node see if it only being deployed one component.\
\
3.1 each service would have a set of interference services, if the adj value is not service level and not direct associate between services then the set would be likely to be the services within the same region. If like consistency then for each service, the set of interference services should be each consistency level between it and another service as well as a chain, s1 -2- s2 -3- s3 mean then s1 has 2 level with s2, s2 has 3 level with s3. Note that the permutation should not be duplicated.\
\
4. category of SLA parameters (for each fine grained service, the could cover any adaption strategy for SLA enforcement, i.e. admission control, resource allocation and task scheduling)\
\
we identify non-functional interference i.e. consistency and functional interference i.e. one service invoke another.\
\
we refer consistency cpu, memory all of there are resources. We see adj and mon variable are all QoS, the goal here is to model objective function for controlling them (both resource quality and measurable quality)\
\
By interference region, we mean the group of QoS objective from number of service that interfere each others, for certain RQ in a interference region, (e.g. consistency) there is need a sequencer for consensus since it is global quality. As long as a RQ of a service being used by multiple PM then it is global.\
\
we define component which consists of find-grained services, component level could also have adj, men QoS, each would need to be considered during MOP solving for any inclusive service. (note that component and service level quality should not be redundant)If a component adj is global then in consensus, it would have different node and possibly different interference region if not all the services of a component are in the same region.\
\
we use hirerichical structure to describe service nested with each other, therefore an interference of a adj of parent service would contain all sub-services, and their SLA should put into the same MOO decision process. If such nested relation is on different component then the at least one service needs to be defined for each component (so that we know such service exist) so we can fine the real one that need to be scale up/down in/out.\
\
adjustable (could be vector)(each associate with cost for each party (cost needs to be normalised by compute % of compared paris, of course need to consider weight), only value that runtime adjustable, always controllable and can not be violated, usually ensure by provider, cost does not have to be fixed, we should always try to determine demand with minimum resource) also associate with interference boundary (services)\
\
only global adj need region and sequencer\
\
         \
\
if the adj is constant value for each service in the interference region, then when apply to equation 2) it can be reduced to one rather than consider all service (i.e. number of replica in VM level)\
eventually we decide to use cpu/memory per component, thus RQ can be component level such as cpu/memory thus all inclusive service would be using the same RQ.\
\
SLA as well but usually can not be violated)\
order error level \
(order error should be as weak as possible since they may be charged, but the consistency requirement is expressed as consistency on mon variable) measurement of order error is the max number of difference to the target service, while measurement of consistency is the max number of different of the same request on different replica as this is easier to be interpreted by human.\
\
\
resource, no of VM (cpu memory etc), PM (for cpu if we can not assign freq, then can assign it based on ECU, e.g. 2.8 GHz may = 2.8/1.2=2.3333 ECU, and change it in granularity of 2.333)\
monetary price willing to pay\
no of invocation (this is actually controllable workload)\
\
monitor able (max capacity is form of (at least one) adjustable or other monitor able (actually we can only consider association with adj as it cover influence to other mon of the same service as well as other from services (either adj or mon), since mon can be translated into adj anyway), may be probability, each with utility point per party
\f1 ,
\f0  also associate with a responsible party when violation cause by certain adjustable value (that is the cost party on adjustable value))\
service time\
response time\
accuracy\
throughput\
\
also have measure metric that usually not in SLA but cloud should ensure:\
scalability\
elasticity\
\
also have other factors not in SLA and usually exogenous  (this can associated with service or region as well, which can only be measured, we can use simple AR to predict this)\
workload\
time\
input size\
\
\
Note that an interference region contain all service in each region of an adj, each region of an adj consist of any service that interfered with a service in that region. Therefore interferences service of a service does not necessary to be all service in that adj region.\
\
monitor able can capture relation amongst parameters, each adjustable may have a boundary region (e.g. consistency region, component region) that capture relation of a service to other serves then in the equation of mapping monitor able  to  adjustable, such boundary region may or may not be used.\
\
Note that provider and com suer can both identify what service should be interfered for a adj value. For com suer, he should provide weight for each service it has, if for provider, the weight for services come from different consumers is define by the total profit = TR-TC of that consumer. \
there are different output of MOO for each region of weight linked services, regardless if they come from the same consumer. \cf2 (therefore no of weight linked services determine number of MOO to be sorted. Only global adj need sub region for sequencer to reach global agreement)\cf0 \
\
(it should be specified if is region level as it always associate with a region, also it need to specify if the adj value is global value i.e. consistency level, if not global then it can by adjusted in each PM. non global value can change on each node, if need to change global one then will effect all node, if such effect violate SLA then corresponding node needs to add in to solve MOO)\
\
after each PM determine there MOOs, for each global adj the final decision is carry out on the sequencer of adj region. We can apply GA again but the change value would be only that adj within the range of min - max for each interfered service, any mon that effect by such adj should be counted in as well. Selection should be applied the same rule as on each PM. 
\f1 (of course one more dimension on no of PM)
\f0 \
\
***************\
QoS and control primitives has 3 measurement function:\
1) measurement on state, e.g. response time (direct), throughput = number of complete service / t (it usually specified by SLA) (this should be the fact, even for consistency. We could measure the max difference between request of a replica to others (e.g. logical clock 7 on R1, but 1 on other, such clock should be reset once max order error reached), then use it to feed model. Such result should be no more than the setup in SSOR) consistency small does not mean response time better, it could be small if workload is small. such relation could be learn by feed fact to dynamic objective model.\
\
\
2) prediction of expected state (before adjustable element change, that is on current adjustable value state) e.g. throughput = number of request / sum of the  response time of each request (sec)\
(for adjustable this would be the assign ones) (objective function note for adj may have more than one adj share the same obj function) (for control primitives, this is a cost function (per-service) )\
\
3) the bounds on SLA (could )\
\
***************\
1) is not used in calculation. On under provision monitoring we only compare 1) and 3), 1) worse than 3) means violation then adjustment need;  On over provision monitoring we compare the adj of 1) and 2), if 1) < 2) then adjustment needed. (may be 1) can > 2) but as long as no mon's such that 1) < 3) then no adjustment needed) \
\
\
adj is over provision primitives and mon is under provision primitives. we can say\
trigger: \
OP = utility of RQ lower than % (when OP the variable change is only the target RQ, of course could be more if there are multiple OPs in the same interference set)\
UP = MQ is violated by % (when UP the variables change are the RQs that associate with the target MQ, of course could be more if there are multiple UPs in the same interference set)\
\
IM may decide for certain interval, a mon is related with no adj, it is possible in which case we simply igonore that mon from objective\
\
but the objectives of service that related to the considered RQ should be included in optimisation due to interference. (note that number of VM may not be considered in OP, therefore in such case VM should be removed when any resource is below default quota, the same for increase VM) \
\
 2) is used when solve MOO, then can determine up/down, and adjust monitor able variable via adjustable variable depends on the equation. (as for how the mon change when adj change can be find out by linear dynamic model, so no need to define i.e y = 1/x) (the up and down can not be changed, i.e if there is need to reduce resource then resource should not be added, so it reduce over optimise a SLA (such as consistency))\
2) may be, can be predefined or learn online using MIMO (ARMA/ARIMA)?\
\cf2 if 2) is region level metric, such as cpu, men then for each service it can be compute via 1) (mean % of cpu usage on service) in fact or auto-created model in 2) need measure value from 1) that is, region level adjustable value can be transferred to service level. \cf0 \
***************\
\
There should be transfer function between 1), 2) and 3)e.g. throughput of a node = SLA throughput/number of node..even availability can be1- number of node * downtime % = overall  availability. However, such may have the drawback that service instance created after a MOP, which may cause the constraint change. We assume that any violation cause by such change should be detected and thus resolve by the next MOP process. Budget is not QoS but SLA parameter, it needs to be distributed and considered separately.\
\
for adj we need to follow the granularity of executor e.g. only allow for each VM/component that such adj is  the same granularity e.g. cpu/memory \cf2 for each adj there also should be a function to transfer the control variable to a form such that the executor accepted (i.e for cpu we can directly assign value to each service and sum them up as the total cpu of VM, we expect the right proposition would be consumed)\cf0 \
\
even using the mutual information (the data should be based on measure ones 1)) to learn interfered service there is still need to define the service boundary. If a control variable is component level then there should be interfered component. (i.e. no of node)\
\
covaraition could be helpful to decide how a RQ affect MQ (asc or desc?)\
\
such model can capture any SLO interference sine any men are represent by adj, then if two men are interfered then all adj of men1 would be contained in men2 and vice versus, then it actually can be replaced as men2 = a*men1\'85 which shows how men1 would influent men2.\
\
\cf2 in order to do comparison and calculation any way, when SLA value, measured value via 1) and adj value used in 2) we need transfer function.\cf0 \
\
note that cpu usage can use unify metric such as ECU to measure.\
\
when train mode we do not consider 0 men since this does not reflect the actual data relations.\
\
we normalise the data as value/ max of the observed value. The proposition between data of interval is still the same. This normalisation only create a base value, therefore even in MOP the new value may be greater, it can still exceed 100% as long as the base value is the same. (in addition we only predict one interval ahead)\
\
5. (partial equilibrium  should always focus on product type) if it is possible to determine how much adjustable parameter is demanded, then we can choosing the best fit type/spot using partial equilibrium of demand supply theory. 
\f1  
\f0  This fit the case where spot instance are used where price change based on supply demand.\
\
Price determine can be based on different consumer (their services) in such case no negotiation is needed as the SLA would always satisfied and reach equilibrium for each consumer. Price should be based on each PM and the granularity of that adj (e.g. component for cpu, memory) as well.\
\
\
budget could be based on each PM, component and consumer as well as adj\
\
can use partial equilibrium for each spot instance type as each product. Seems like amazon does not allow scale up - purchase a type still charge the whole regardless if you fully using it. can consider fine grained resource to prices per cpu/memory.\cf2  (we can calculate demand/supply function dynamically - demand function Q = b - Pa, supply function Q = d + Pc, (to get b,a,d and c can use 
\fs38 \uc0\u8234 Linear least squares\uc0\u8236  
\fs24 (polynomial regression)) then\cf0  \cf2 it can be used MR = MC, MR = quantity times demand function
\f1 ,
\f0  therefore the demand resource would definitely being produce with a assumption of profit maximum) remember to consider case where there is no equilibrium point within the quantity range, then usually select the max of demand. \cf0 \
\
\cf2 for the first interval, the demand/supply function would be calculated by a set of the (budget of each region adj type)/ total quantity of that adj type in each interval. Then the subsequence interval can use the calculate equilibrium point price and the total number of adj value in each previous intervals. \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 \
\
When demand function is known we calculate price = P = (PED/(1+PED))*MC, PED = P/Q * dQ/dP. Then for each individual of MOO we set criteria: budget >= sum of each service of the calculate equilibrium price based on current amount of adj * amount of adj, in order to verify its feasiablity. \
we can calculate the demand function Q = b -Pa by using training data of final Q,P by each MOO interval end. \
\
one MOO can have more budget function as well if it cross different consumers.\
\
when apply demand/supply with MOO we may need finer grained price (instead of per hour, we may need per sec etc.)
\f1 \
 \

\f0 5.1. \cf2 when under supply, calculating the ratio of capacity (cpu/memory, for the additional demand) can be also used to reduce the most suitable instance type (e.g. most expensive fits the ratio) when over supply
\f1 ,
\f0  also increase the most suitable type (e.g. cheapest and require less number of type) (the solution for if scale up or scale out could potentially be determined as well). When it can't add more on the VM it seeking to add more PM with suitable type. (all those output should be involve in the solution of MOO)\cf0 \
\
assign resource to service as instance type, although the resource may not be fully used buy this is how the price is calculated. instance type can be scale up/down to another type\
\
6. with 2
\f1 nd 
\f0 order ARMAX and least squares algorithm, we can dynamically model relationship between monitroable value and adjustable value, giving mon(k) = a1mon(k-1) + a2mon(k) +  adj(k) +  adj(k-1) \cf2 + d(k-1) + d(k-2).\cf0 \
\
adj(k) = sigma An1*adjn1 (n = no of services for adj1) (k)+ sigma An2*adjn2 (n = no of services for adj1) (k) + \'85\'85. sigma Axc*adjxc (x = no of services for adjc within interference domain of target service) (k), c = no of adjustable value that associate with m Axc = row vector, adjxc = column vector\
(this can be either adj value or mon value)\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf2 d(k) = sigma An1*dn1 (n = no of services for with in the region of associated adjustable values) (k)+ sigma An2*dn2 (k)  + \'85..sigma Axc*dxc (x = no of services for with in the region of associated adjustable values) (k), c = no of exogenous parameter such as workload. Axc = row vector, dxc = column vector\cf0 \
\
least squares algorithm can solve this by building partial derivation of S (sum of error) = 0, for solving each a1,a2,And the number of equals needed  = 2 + 2 sigma Ki (i=1,2 \'85 c) K = no of service for each interference domain of adjustable value for a service, i= no of different type of region for adjustable value\cf2  + 2 * exogenous parameters * no of all services involved (get rid of the redundant ones).\cf0  This is the minimum required number of measurement as well. (not duplicated monitoring)\
\
update the model and apply the model can be done on each interval k, but adj and mon needs to be normalised (such as use mean value or % of total), \cf3 or we can update model on each request, so may be better capture the case where violation and over provision occur (the AR worth be still using measure value from previous k-1 interval) and then only apply it on k invertval, normalisation is still needed. (this is experiment driven) \cf0 Adj value also needs to be normalised,  when req time decrease resource should be increase such that req = 1 / resource etc.\
\
for each interval k, if no request to a service but still it would be used for calculation but at k time step the coefficient would be 0.\
\
\
to decide wether use ARMA/ARIMA/ARMAX is a experiment driven task.\
\
upon SLA violation, this can seen as a trigger of interval k change, such as spike load or the up/down turing point on workload graphic.\
\
like in ANN we can also use step-wise approach to determine the number of order\
\
in symmetric uncertainty, for new or removed control primitive, the interval that it is unavailable would be represented as value 0. And garardunlly, it can be determined as sensitive/insensitive\
\
7. to make the model even more generic and flexible, one does not need to know which adj/mon value can influence mon value, it can be learn online via AIC/RS and maximum likelihood method, as well as stepwise algorithm. (of course the sample time of finding the number of parameters would be longer than finding the coefficient)\
\
\
8. the main difference between ANN and ARMA is that ANN capture nonlinear relation. However, since the model is updated in very short epoch, therefore it is possible to capture local linear relations. ANN needs to determine no of nodes in hidden/input layer and no of hidden layer, as order in ARMA. They can be also dynamically defined via AIC/RS. When apply ANN we apply the same as ARMA: relevant mon and adj values as input (including interference services), a mon as output. \
\
When use BP, there is need to compute MSE of all sample up to k interval, so that to decide if update the weight in k interval and the current model is always with min MSE. Or we can use infinite run of training until the errors is below a certain value or the max number of iteration has been reached.\
\
we apply AIC/RS and stepwise/incremental selection on ANN we can assume 1/2 hidden layer (as 2nd order on ARMA), then only go through combination of input and hidden neurone \
\
\'93It has been mathematically proved that the single-hidden \
layer feed-forward networks are universal approximators \
that can learn any continuous functions with arbitrary \
accuracy\'94\
\
\cf2 for training ANN we assume weight can be learn online therefore on each training interval we only need to determine no of input and no of neurone and activation function (no of layer is set to 1 or 2). whose value not less than the min AIC/RS in the history. Therefore instead of finding the optimal model in one run, we only interesting in finding the best ever model and eventually reach to the best model.  (learning rate would be fixed, as we can have infinite samples) \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 this selection is only for ann, when the mutual information finds changes then model is re-selected. Find the best RS for each model. (ARMA can use it to find order) (for efficiency selecting ANN can use similar way to PROP where select granularity change on the fly)\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf2 An incremental model selection could be applied, i.e. (start with full input) chose the number of neurone of a hidden layer that best than the best historical AIC/RS (or just the best one if the target couldn't find ), then do it only the next layer, then reduce the input one by one. Note that the RSS should be base on the new model on the give interval (with the data in the buffer windows). Or we can consider all combination via backward approach.\cf0 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf4 (instead of AIC, we may apply the least RSS seems we only interest in accuracy and the speed of converge, if only apply RS ann can only run 1 round to see number of neruos), mutual information is a good way to predict interference set and related resource quality.\
t\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 train ann we can train a model using step-wise approach, that is, setup worst RS and RMAPE and record any model that produce higher than that. Increase the number of neurone until the increment does not provide better model. Of course to prevent training forever, a max training time is needed such that the best ever model is returned if such time is reached.\
\
The above is only for the same ANN structure, for subsequent only need to train form the selected number of neurone and return as long as it get the RS and RMAPE  better than the worst one. If the structure change then the entire process should be repeated.\
\
with predefined accuracy 
\f1 (the chance that SLA violation occur)
\f0 , we can even dynamically chose either ARMA or ANN.\
\
We could apply a buffer windows, so we won't running out of memory to store historic data. This is applicable since the old data can not represent current dynamics.\
\
all monitor of each adj should be kept even they are not used since the next aic run may decide to use some of them so that previous data set can be used. also may be better to use normalised monitoring data? or attempt to use smaller number as possible\
\
If apply ACO then there is need upper/lower bound on all QoS, especially resource quality therefore 
\f2\fs26 heuristic factors can be found by output of RQ value/sum of outputs of all other RQ value (if smaller is better the can be 1 - the above)\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf5 we can even have a sequencer/planner for each interference set, it is used to decide global RQ involve MOP. We do not consider cross PM service interference. Therefore MI only search locally (or only on the same VM). Only accept predefined cross PM interfered service. sequencer  is used when the MOP should be solved globally (involve global RQ).\cf0  (or if possible, try use MI to iterate every service in the cloud, this is carry on on each node, of course should exclude its own replica, we need to ensure the training sample time is the same, thus only consider the leap time) \
(one leverage is to only consider services on the same PM, as well as the services instance that required by target service)\
\
as opposed to sequencer, we can possibly apply a decentralised manner, since the node that willing to optimise would automatically being a sequencer, then all the objective related to global RP would be considered. However, the dynamically changing QoS model needs to passing through to the temporarily sequencer. (to repeat, the sequencer is mainly for collecting QoS model from different node) of course if the objective is under optimising then any further trigger would be ignored.\
\
not that the primitives which interfere a QoS could be changed even cpu, memory could be remove if they are not significant\
\
note that for the abstract qos model, the the training data can be composite 
\f1 (could be sequential, parallel, loop and conditional etc.)
\f0  or atomic service as long as it gives enough sensitive set of control primitives (that is all the significant inclusive services are identified by the middleware) and the training data are fed correctly.\
\
\
We can conclude all the control primitives into a aggressive 'cost' as an objective function (that is sum of each provision of control primitives' objective function) when solving MOP. but the restriction of each resource would need to be considered \
\
9. In MOO the selection rule could be: (non dominated and crowd distance)/ assigned weight (if any)\
weight include: 1) amongst services from different consumers, 2) services from the same consumers 3) amongst different adj/mon value from the same service\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f3 \cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0 \cf2 when determine global value on sequencer, it may not have weight on each node, (we first ensure SLA are all meet) therefore would need to determine on the least sum degradation i.e. how much the mon are worse than local decision when apply certain global adj value, then pick up the smallest one. (if we use weight) or can simply use domination ranking. (of course need to reexamine any constraints that effected such as budget)\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 \
when consensus on adj we can agree on different level of region concurrently, i.e no of PM and consistency \
\
Some adj from different MOO (or ven the same MOO) may needs to compete with each others (i.e. cpu/memory) when such competition occur we first satisfy the ones that have more profit, then looking to add more PM normally add 1, the same as when a PM usage below predefined value which cause it can be removed. \cf2 in this case we know how much resource needs thus add on the proper VM  otherwise from the cheapest one . (need to send to sequencer for determine) 
\f1 no action if node already decided to be added) (PM section could based on availability)\cf0 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f3 \cf0 when add new PM we may or may not know how much resource demand, if unknown we use the cheapest VM, the budget would be equally grained from the current PM who propose to add new one (or in ratio if how much is known). As during MOO this should be a constraint on each PM.\
\
at the end of each run of MOO needs to rebalance the remaining budget, based on the goal that every node should have equally free budget. The overall budget would not exceed the consumer anticipation.\
\
the SLA bound would be distributed as well if applicable e.g. throughput\
\
such distribution can be done in a decentralised way after each adj has been finally decided.
\f0 \
\
when we need remove PM, remove the ones that use least resource. and equally distribute the budget\
\
In MOO, the objective could be each SLO + min the cost, of each service we could sum up cost/mon of all adj value so that reduce the number of objective. for consistency only sum up the consistency that a target service needs to maintain when another service arrive first. Therefore assume each service has the same number of SLO, the complexity of objective is 2 * S \
\
or we can use the maximum adj * S +  mon * S (more detail strategy) (may be with objective selection?) that is consider each mon and adj for each service. 
\f1 (for some adj such as resource would be component level therefore would be one for each component)
\f0 \
\
We assume that even when SLA of mon has been satisfied, the consumer still wish to pay more in order to optimise the mon. Subject to budget\
\
mutual information (define how much dependency) and covariation (decide if conflict or redundant) (the data should be based on measure ones 1)) can be used for objective reduction, does not need to be with MOO optimiser.\
\
the objectives for each group could be QoS + total cost of each instance, if sharing RP e.g. CPU then the cost of it is equally proportioned to each instance.\
\
==================================================================\
\
dynamic MOP can be see as static MOP for each point in time, therefore can be solve using traditional approach. GA may need to consider re-evolve but ACO seems like capable to handle change of objective, another factor is that the interval t of optimisation needs to map with the time taken to search (although the trigger is defined by the over/under utilisation, but we can decide if we need to start the metaheristics)\
\
In ACO even it is optimise a single objective, each ant would select a RP for all objective even it is not sensitive by the current objective. Such RP's heuristic factor could determine its preference. Each ant would eventually have a solution, which is an individual. Therefore at each round, ACO would produce a pareto set, and all the sets from all rounds are combined together to form a larger pareto set, which then sorted and non-dominating and crowding distance to have the pareto optimality.  
\f1 (the best solution for each objective is selected based on 
\f0 their value, only the best solution is allowed to update pheromone factor
\f1 )
\f0 \
\
(
\f4 pheromone factor is more like the preference of a certain objective, whereas heuristic factor is more like preference of how it affects to the global objectives.
\f0 )\
\
\
it is possible to integrate the dynamic economic equilibrium model with ACO, upon a solution we used the decided RP price, then the decided price is based on trade-off RP.  assume distinct price for each service instance._\
\
when allocating RP, it is possible to limit to certain type, e.g. a VM has 128MB, 1 core CPU, 100 concurrency. so that the MOP process can face less option. At the extreme case (arbitrary possibility) such type never exist then the search space would be every possible value. (continuos and descret)\
\
When select a RP, other RP use the current provision value. If RP from external service is uncontrollable then simply use the provisioned value. For EP, if changes, there is need to update with the latest one (same as QoS sensitivity model change, the existing pareto sets needs to be re-evaluated, also he rustic factor needs to be updated, possibly, we could update the pheromone factor as well (just iterate all solutions again, based on each iteration from the 1st to last)).\
\
may be different optimisation group could be seen as different colony? ACO is more suitable than GA because it is better in terms of handling dynamic/continuous optimisation, and potentially good at many objectives (as each ant works in paralleled)\
\
in ACO all the solutions are recored till the last and then sort, this is due to dynamic change of objective function which case 'which is better' could be changing.\
\
for improvement and degration of objective, we use the ratio better achieved value and the predicated value of that objective before optimisation. (use predicted value even such has been violated)\
\
even though only one ant for an objective, it needs to determine RP which does not required by this objective, but during pheromone update it updates 0.\
\
An ant randomly select an objective therefore each objective could have more than one solution each iteration. the number of ant should be > the number of objective (or we make sure each objective is optimised by at least one ant each iteration) All the sensitive RP and objective should be considered together to avoid lock-in on local optimisation solution.\
\
our aco only uses non-dominated sort at the last stage, therefore modify it does not affect diversity of searching solutions. (so we can set the extreme value of crowd distance is 0 instead of infinite) (or use ranking dominance?)\
\
when constructing solution, the sequence of RP for ant could be random, if when select a PR any constraints violated, then this particular RP would needs to be reselected without the previous RP candidate that cause violation. if all candidates are cause violation then go back to previous RP. The sequence of selecting RP could be random, so if an ant suicide then the next ant may not be trapped in the same way. (should we say we have two ants: the normal ant and the guidance ant which assist the normal ant regarding which RP should be consider next)\
\
for each objective (normal ant), the guidance ant could maintain another pheromone, which is updated as fixed value *  the number of successful ant that select such RP as the ith RP to search. (this probability is determined on pheromone  factor only, and its update could be local update only)  this need the min/max pheromone value as well. Note that this guidance ant only effect the efficiency to produce a valid solution not quality of the solution. Thereby it uses a different pheromone structure as the normal ant.\
\
each ant would have a suicide time if so time reach it stops regardless if the solution has been completed. If concurrent then only global pheromone update is needed.\
\
It may be possible to add local pheromone update (for diversity): for all ants for the same objective, update a fixed value for local one of a candidate based on how many ants have selected such candidate. If it is under concurrency it may have little useful. (see various qos for workflow paper) note then local and global update are updating the same pheromone value.\
\
our ACO is MAX-MIN ant systems thereby we need to define max/min pheromone value.\
\
may be worth to compare the produced solution with existing one to make sure it is really better\
\
when the solution can not be found (always constraints violated) by trying every candidate of an input. if it is the last input for such constraint, then it would go back to each input of that constrain, try every candidate. If it is not the last one, then it will let the guidance ant to select another CP to search. If still cause the violation even when try every possible combination of inputs for a constraints, it  then start the normal ant again for a better sequence. Of course once the time is reach such ant should be suicide.\
\
when QoS model changes, ACO can re-evaluate even when there are new primitive/phase out primitives, it just simply go through the selection process only for the new primitive.\
if it is a merge of two local optimisation, then the process only need to validate the constraints and remove the solutions that violate them. This case, however could affect performance of ACO, we observed that the case of  new primitive/phase out is unlikely to happen frequently\
\
\
The training data (demand) can be different from control (provision), but they are assumed to be able to be mapped together. e.g. security policy (provision), the level of risk (demand) or the computational resource and different instance type to be matched.\
\
\
we could adopt two form of ACO - 1 has weight and 1 is weight-free. This only require to change the heuristic factor formula and change crowdoing distance to weight sum formula.\
\
To determined which objectives are conflicted when optimisation, not only the models of depends-on instance, but also those that deployed on the same VM as depends-on instance should be considered. Also, should consider those instances that uses global CP\
\
based on current strategy, the scale in/out are based on scale up/down (e.g. not enough on PM or no hardware CP is needed on a PM), but in future it is possible to design more 
\f4 sophisticated\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0 \cf0  techniques for scale in/out (this may need a centralised control) this is sufficient because:\
\
1) VM allocation require centralised control\
2) optimising the cal up/down could help to reach global minimised in/out as well. (e.g. min the number of VM)\
we consider the VM allocation for best global resource usage as a separated problem\
\
\
cost like CPU is proportioned to each service-instance of VM, (they all be considered in the same objective group for sure), thus when decide to need new replica, the extra portion of budget can be equally allocated to the new replica (as decided by ACO), then the post-balancing of available budget can be triggered. For other CP that still sufficient, we can cut the default amount to the new replica.\
\
QoS sensitivity is identified via CP and EP, and it is selected from same VM and 
\b required by
\b0  service-instances.\
\
Conflcting objective is identified via CP, and it is selected from:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f4 \cf0 1) directly or indirectly 
\b interact with
\b0  the service-instances on the attached PM\
 2) deployed on the attched PM and those that on the same PM as the interacted service-instances;\
 3) from other VMs but sharing the same CP with service-instance on the attached PM (i.e. a global control of load balancing policy for all instances of a service).\
4) we only consider nonpartitionable CP amongst PM under VM interference. \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0 \cf0 \
\
using demand not provision value, for a CP provision decision X, we can tell least X more likely to cause under provision whereas higher X more likely to over provision.\
\
\
why not MAPE?\
\pard\pardeftab720
\cf0 Calculating an aggregated MAPE is a common practice. A potential problem with this approach is that the lower-volume items (which will usually have higher MAPEs) can dominate the statistic. This is usually not desirable. One solution is to first segregate the items into different groups based upon volume (e.g., ABC categorization) and then calculate separate statistics for each grouping. Another approach is to establish a weight for each item\'92s MAPE that reflects the item\'92s relative importance to the organization\'97this is an excellent practice.\
\
\
Note that generally, for services chain in the cloud we assume SLA for the whole chain can be spliced to each of the inclusive service. However, if not, we can apply certain function (input as QoS of each service) in the constraints to calculate the global expected QoS.\
\
\
exclude irrelevant primitives is a good way to reduce over fitting problem already!\
\
we can move the optimisation to global in terms of PM, considering VM interference. But whether certain services from different VMs should be optimised in one optimisation loop depends on whether they are truly correlated. (The QoS sensitivity model). Note that in terms of resource competition, we may not be able to follow FCFS (for different VM in the same optimisation group) but follow the way to minimising the number of service that needs to be replicated. We assume all CP are charged on the same price no matter type of PM/software stack, then on the new VM these services would be continuously modelled and optimised by our adaptive approach.\
\
for dynamic ACO, instead of having a solution archive, we can only have a short memory, K, at each iteration t, for each objective, the best number of K solution  is try to replace the entires of that memory from t-1. The pheromone of new ones are increased whereas removed on are decreased as constant value (e.g., (max-min)/K). This can increase diversity and it is a randomised way to cope with dynamic. Of course at the final stage only the best of each objective can be put into the pareto front.\
\
after the above actions, the memory from t-1 can be mutationed and generate new solution (memory based)\
\
for objective finder, we can maintain a objective topology (based on if sensitive to same CP (directly or indirectly)) in each local autoscaler. This regional concept not only help to reduce centralisation in distributed environment, also help such reduction on a particular PM (node). Each autoscaler only interested on the services deployed on corresponding VMs/PM.\
\
MAPE not cater for modelling, model@runtime not used for optimising, DDDAS cater for both. model@runtime may only consider requirements change (which is part of our consideration), but not how the system behave under fixed requirements.\
\
even if some software CP is not charged, so we do not care their over provision (as they can be still used by other service-instance, even they are assigned to one instance, unlike hardware Cps, in case they are charged, think of the case of broadband charge), we should still find the best combination of them and other CP, since a good software CP may require less hardware CP, which can be used by other VM.\
\
the frequency of model selecting and training could be different to frequency of measurement (interval) e.g., measure every interval but select and train every 10 intervals, feed data for all these 10 intervals for training and selecting.\
\
for CPU and memory we measure demand via average whereas use max for thread, this is because software CP has more closed and direct impact to service than hardware CP. So we measure the demand more restricted. \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 ==================================================================\
\
\
10. as the economic road map suggests, IaaS, Paas is more likely to be monopolistic market while SaaS would be monopolistic competition.\
\
price is different for each service instance of a consumer \
\
the reasons to make budget on each node is: it allow local computation get rid of consensus of the same type of PM. as solve it centrally is the  same as solve it distributedlly. But the demand function of each node can better capture the true demand. \
\
cost = price * (stand by power + power per resource * the resource a consumer use) (e.g. cpu frequency, price here are from utility provider)\
\
(how to find power per resource refer to 'enery-cost', we can use approximate value since this is out of scope)\
\
unlike previous work, we assume what the user willing to pay depends on his/her maximum budget and the trade-off decision of QoS optimisation, which implies that the users do not have to spend all his/her possible budget.\
\
\
When change RP provision we could either stop-start the VM or doing live migration on the same PM (if on-the-fly allocation is not allowed). may be we should add by yes combination of resource we imply vertical and horizontal scaling. (how much we need the scale?)\
\
\
11. on architecture, we can use DDDAS, and for the trigger of optimisation, we can do either reactive (based on measurement, can be used for both under and over) or proactive (based on prediction) mainly for under. \
\
Experiment driven:\
1) ARMA/ARIMA/ARMAX? (if include workload)\
2) if there is need to apply AR on workload? or simply based on last interval's workload? \
3) the way to forward/backward search on ANN model, if need to try every combination?\
4) if apply dynamically determine if use ANN or ARMA? or choose one only?\
5) if apply time series on ANN?\
\
for demonstrating problem we need to \
1) show benefit of fine grained\
2) in terms of interference between services we mean 1,the original approach consider only one service is broken as it is interfered 2,  change one control of a service may interfere another service.\
\
such interference could be conflict interference or concord interference\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf2 we may use the term QoS conflict to describe all the interference, sine response and throughput are both conflict with resource QoS, and this is more suitable for MOP. \cf0 \
we can use resource  and use consistency (positive correlated in terms of performance objective and negative correlated (conflict) in terms of consistency and resource usage objective) as example. We also need to show vertical and horizontal interference for both. 
\f1 (in this case the use of MOP is because it support conflict optimisation)
\f0 \
\
we can also in 2) to demonstrate the issue of trade off\
\
conflict usually between mon on same or different service and adj of a service, concord usually between mon of a service and mon on same or different service\
\
\
for accuracy experiment, can change the control value and measure the actual mon and the output mon of model. Or can only change workload etc, measure both mon and adj, then apply adj to model and compare the actual mon and output mon of model, in such case we can use 70% data to train and 30% to test. \
\
or since we aim for online dynamic model, we can simulate online through the entire workload distribution, see if the model perform well from less data to more data.\
we can use both of the above simulation for accuracy and adaptivity.\
\
\
\
for MOO experiment, we first need to proof our approach can reduce SLA violation by comparing the   different SLO over the entire workload, scalability and elasticity can be evaluated here. Then we can apply general approach i.e. static to compare 
\f1 (those does not consider conflict, service inter fence and equilibrium) 
\f0 SLO, (if optimal) and profit (if maximised). example of comparison can see \
\
\
HPL-2008-123R1-mimo\
\
\
Assumptions:\
\
SLA model\
System model e.g. VM, PM\
price model\
\
need provides:\
\
transfer function\
\cf2 transfer function to executor\cf0 \
component/service (we use cpu/memory per component)\
cost function\
default min resource on a VM (use to determine if remove such VM)\
if a RQ is global\
\
b8:8d:12:1c:32:5a \
7300\
\pard\pardeftab720
\cf0 \
\
xinxin8866@live.cn\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 244812319\
\pard\pardeftab720
{\field{\*\fldinst{HYPERLINK "http://video.fc2.com/a/content/20120213gJExCDLr"}}{\fldrslt \cf0 http://video.fc2.com/a/content/20120213gJExCDLr}}\
\pard\pardeftab720
{\field{\*\fldinst{HYPERLINK "http://www.cs.duke.edu/~angl/papers/cloudprophet_tr.pdf"}}{\fldrslt \cf0 http://www.cs.duke.edu/~angl/papers/cloudprophet_tr.pdf}}\
myllxgmt\
\
\pard\pardeftab720
{\field{\*\fldinst{HYPERLINK "http://video.fc2.com/en/a/content/20130216b2PCaS04"}}{\fldrslt \cf0 http://video.fc2.com/en/a/content/20130216b2PCaS04}}\
\pard\pardeftab720
{\field{\*\fldinst{HYPERLINK "http://www.xvideos.com/video1153631/hot_young_sexy_teen_is_the_best"}}{\fldrslt \cf0 http://www.xvideos.com/video1153631/hot_young_sexy_teen_is_the_best}}\
\
\pard\pardeftab720
{\field{\*\fldinst{HYPERLINK "http://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm"}}{\fldrslt \cf0 http://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm}}\
\
\pard\pardeftab720\sl320

\f5\fs22 \cf0 326ZT4K7
\f0\fs24 \
\pard\pardeftab720
\cf0 \

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth21800\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640

\itap2\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clwWidth2180\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clmrg \clvertalc \clshdrawnil \clwWidth2180\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\sl320

\f6 \cf0 Thank you for yui mizuna your order, your application has been processed.\nestcell 
\pard\intbl\itap2\nestcell \nestrow

\itap2\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clwWidth21800\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clmrg \clvertalc \clshdrawnil \clwWidth21800\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\sl320
\cf0 \'a0\nestcell 
\pard\intbl\itap2\nestcell \nestrow

\itap2\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth2180\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth19620\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\sl320
\cf0 \'a0\nestcell 
\pard\intbl\itap2\pardeftab720\sl320
\cf0 Your Order Number is: 10138825\nestcell \nestrow

\itap2\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth2180\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth19620\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\sl320
\cf0 \'a0\nestcell 
\pard\intbl\itap2\pardeftab720\sl320
\cf0 Your Membership number is: 8165405\nestcell \nestrow

\itap2\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth2180\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth19620\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\sl320
\cf0 \'a0\nestcell 
\pard\intbl\itap2\pardeftab720\sl320
\cf0 Your Master Card card will be charged $12.00\nestcell \lastrow\nestrow\cell \lastrow\row
}